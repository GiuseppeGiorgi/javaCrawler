# java Crawler
Progetto open source di un Crawler in java.
Questo progetto permette di scansionare un intero sito web seguendo le regole di navigazione del Robots.txt, 
per ogni pagina vengono salvati dei dati(esempio: tag h1, h2, title, description ecc..) su un file csv,
tutte le impostazioni vengono gestite tramite un file .properties

##Start
Per usare il progetto su un qualsiasi sito web basta configurare il file 




## Uml

  <img src="/UML/diagram.png" width="500"/>  
